{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "def load_word2vec_model(path=\"/kaggle/input/google-word2vec/GoogleNews-vectors-negative300.bin\"):\n",
    "    model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "    print(\"Word2Vec model loaded!\")\n",
    "    return model\n",
    "\n",
    "model = load_word2vec_model()\n",
    "\n",
    "def get_similar_words(word, model, topn=2):\n",
    "    if word in model.key_to_index:\n",
    "        return [w for w, _ in model.most_similar(word, topn=topn) if w.isalpha()]\n",
    "    return []\n",
    "\n",
    "def enrich_prompt(prompt, model, max_sim=2):\n",
    "    enriched_words = []\n",
    "    for word in prompt.split():\n",
    "        sims = get_similar_words(word, model, topn=max_sim)\n",
    "        enriched_words.append(f\"{word} ({', '.join(sims)})\" if sims else word)\n",
    "    return \" \".join(enriched_words)\n",
    "\n",
    "def generate_response(prompt, model_name=\"llama3-70b-8192\"):\n",
    "    print(f\"Simulated response for: {prompt}\")\n",
    "    return f\"Response to: {prompt}\"\n",
    "\n",
    "def analyze_responses(orig, enriched):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    matrix = tfidf.fit_transform([orig, enriched])\n",
    "    score = cosine_similarity(matrix[0:1], matrix[1:2])[0][0]\n",
    "    print(\"\\n==== Response Analysis ====\")\n",
    "    print(f\"Similarity Score: {score:.4f}\")\n",
    "    print(f\"Original Word Count: {len(orig.split())}\")\n",
    "    print(f\"Enriched Word Count: {len(enriched.split())}\")\n",
    "\n",
    "original_prompt = \"Describe the future of artificial intelligence in healthcare in 2 concise bullet points.\"\n",
    "enriched_prompt = enrich_prompt(original_prompt, model)\n",
    "\n",
    "print(f\"Original Prompt:\\n{original_prompt}\")\n",
    "print(f\"\\nEnriched Prompt:\\n{enriched_prompt}\")\n",
    "\n",
    "original_response = generate_response(original_prompt)\n",
    "enriched_response = generate_response(enriched_prompt)\n",
    "print(f\"\\n==== Original Response ====\\n{original_response}\")\n",
    "print(f\"\\n==== Enriched Response ====\\n{enriched_response}\")\n",
    "analyze_responses(original_response, enriched_response)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
